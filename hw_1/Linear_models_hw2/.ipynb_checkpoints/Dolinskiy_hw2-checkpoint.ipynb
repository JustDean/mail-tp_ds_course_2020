{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOaN-4dZ1GAl"
   },
   "source": [
    "# Импорт и функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LapSqNSSTt2s"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(11.7*2,8.27*2)})\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "P_YQLq9da6qq"
   },
   "outputs": [],
   "source": [
    "# создаем датасет куда в дальнейшем будем записывать показатели моделей.\n",
    "\n",
    "results = pd.DataFrame(index=['GaussianNBbaseline', 'GaussianNBnoCat', 'GaussianNBwithCat',\n",
    "                              'LogisticRegressionBaseline', 'LogisticRegressionNoCat', 'LogisticRegressionWithCat',\n",
    "                              'KNeighborsClassifierBaseline', 'KNeighborsClassifierNoCat', 'KNeighborsClassifierWithCat'\n",
    "                              ], columns=['Accuracy', 'ROC-AUC', 'Training_time', 'Prediction_time'])\n",
    "\n",
    "log_res = LogisticRegression()\n",
    "bayes = GaussianNB()\n",
    "k_neighbour = KNeighborsClassifier()\n",
    "\n",
    "\n",
    "def models_coach(models):\n",
    "  for label in models:\n",
    "    start = time.time()\n",
    "\n",
    "    model = models[label]\n",
    "    model.fit(X_train, y_train)\n",
    "    end_fit = time.time()\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    predict_end = time.time()\n",
    "\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    auc = roc_auc_score(y_test, predictions)\n",
    "\n",
    "    training_time = end_fit - start\n",
    "    prediction_time = predict_end - end_fit\n",
    "\n",
    "    results.loc[label, 'Accuracy'] = accuracy\n",
    "    results.loc[label, 'ROC-AUC'] = auc\n",
    "    results.loc[label, 'Training_time'] = training_time\n",
    "    results.loc[label, 'Prediction_time'] = prediction_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JJDvcaiNT6Ul"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./weatherAUS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BQiamTZJUDRC"
   },
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IBg2TsYXUVlZ"
   },
   "outputs": [],
   "source": [
    "# data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EVuIyMU7UYts"
   },
   "outputs": [],
   "source": [
    "# data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z2CjCKEOWi_4"
   },
   "source": [
    "# Способ 1\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "1. Выкидываем колонну с датой и локацией.\n",
    "2. Заменяем пропущенные значения самым часто встречающимся (модой) для каждой   колонны.\n",
    "3. Используем one-hot-encoding на категориальные данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tbzvMlc7U_nl"
   },
   "outputs": [],
   "source": [
    "data_copy1 = data.copy()\n",
    "data_copy1 = data_copy1.drop(columns=['Date'])\n",
    "data_copy1 = pd.get_dummies(data_copy1, dummy_na=True)\n",
    "data_copy1 = data_copy1.fillna(data_copy1.mode().loc[0,:])\n",
    "# data_copy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "s6U8NOkoXTtU"
   },
   "outputs": [],
   "source": [
    "X1 = data_copy1.drop(columns=['RainTomorrow_Yes', 'RainTomorrow_No', 'RainTomorrow_nan', 'RISK_MM'])\n",
    "y = data_copy1['RainTomorrow_Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "f13rPXKIWcZs"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size=0.25, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "j6GizDmxYKy3",
    "outputId": "fc5738b0-89fb-4244-8883-3a356b8bb288"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Dean\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "models = {'GaussianNBbaseline': bayes, 'LogisticRegressionBaseline': log_res, 'KNeighborsClassifierBaseline': k_neighbour}\n",
    "\n",
    "models_coach(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-nKdWiwfDAO"
   },
   "source": [
    "# Способ 2.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "1. Заменим пропущенные значения модой.\n",
    "2. Избавимся от коррелируующих признаков.\n",
    "3. Отскалируем признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "A4POkaqFftZq"
   },
   "outputs": [],
   "source": [
    "data_copy2 = data.copy()\n",
    "data_copy2 = data_copy2.drop(columns=['Date', 'Location'])\n",
    "data_copy2 = data_copy2.fillna(data_copy2.mode().loc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "mmUhIhLWf4-D"
   },
   "outputs": [],
   "source": [
    "# data_copy2_non_categorical = data_copy2.drop(columns=['WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow'])\n",
    "# sns.heatmap(data_copy2_non_categorical.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QJoO3sldgiX9"
   },
   "outputs": [],
   "source": [
    "X2 = data_copy2.drop(columns=['MaxTemp', 'Temp9am', 'Temp3pm', 'Humidity9am', 'WindSpeed3pm', 'Pressure9am', 'RISK_MM'])\n",
    "X2 = pd.get_dummies(X2, drop_first=True)\n",
    "X2 = X2.drop(columns=['RainTomorrow_Yes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "UkWyxSu9oYFP"
   },
   "outputs": [],
   "source": [
    "X2 = preprocessing.StandardScaler().fit_transform(X2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, y, test_size=0.25, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "F5GvU3IpqGDo"
   },
   "outputs": [],
   "source": [
    "models = {'GaussianNBwithCat': bayes, 'LogisticRegressionWithCat': log_res, 'KNeighborsClassifierWithCat': k_neighbour}\n",
    "\n",
    "models_coach(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUijNlGqqz8b"
   },
   "source": [
    "# Способ 3.\n",
    "\n",
    "---\n",
    "\n",
    "1. Повторим способ 2 без категориальных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "9hDpzqGcq8Sg"
   },
   "outputs": [],
   "source": [
    "X3 = data_copy2.drop(columns=['MaxTemp', 'Temp9am', 'Temp3pm', 'Humidity9am',\n",
    "                              'WindSpeed3pm', 'Pressure9am', 'WindGustDir', 'WindDir9am',\n",
    "                              'WindDir3pm', 'RainToday', 'RainTomorrow', 'RISK_MM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "JvaetGJsw0vh"
   },
   "outputs": [],
   "source": [
    "X3 = preprocessing.StandardScaler().fit_transform(X3)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X3, y, test_size=0.25, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "puZHH2qiq8Uz"
   },
   "outputs": [],
   "source": [
    "models = {'GaussianNBnoCat': bayes, 'LogisticRegressionNoCat': log_res, 'KNeighborsClassifierNoCat': k_neighbour}\n",
    "\n",
    "models_coach(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLsLbkkUzIoP"
   },
   "source": [
    "# Вывод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "id": "mbQJtPc71cG3",
    "outputId": "e4a2ad10-74ce-46f3-c985-fbbe99b7553c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>Training_time</th>\n",
       "      <th>Prediction_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GaussianNBbaseline</th>\n",
       "      <td>0.748094</td>\n",
       "      <td>0.745322</td>\n",
       "      <td>0.362021</td>\n",
       "      <td>0.146008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNBnoCat</th>\n",
       "      <td>0.83572</td>\n",
       "      <td>0.732009</td>\n",
       "      <td>0.0370018</td>\n",
       "      <td>0.0110009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNBwithCat</th>\n",
       "      <td>0.772455</td>\n",
       "      <td>0.734941</td>\n",
       "      <td>0.138008</td>\n",
       "      <td>0.0600033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegressionBaseline</th>\n",
       "      <td>0.847056</td>\n",
       "      <td>0.684625</td>\n",
       "      <td>2.38414</td>\n",
       "      <td>0.0290015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegressionNoCat</th>\n",
       "      <td>0.851023</td>\n",
       "      <td>0.69869</td>\n",
       "      <td>0.130008</td>\n",
       "      <td>0.000999928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegressionWithCat</th>\n",
       "      <td>0.851529</td>\n",
       "      <td>0.713009</td>\n",
       "      <td>0.52303</td>\n",
       "      <td>0.00500011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifierBaseline</th>\n",
       "      <td>0.832794</td>\n",
       "      <td>0.701302</td>\n",
       "      <td>17.538</td>\n",
       "      <td>140.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifierNoCat</th>\n",
       "      <td>0.831444</td>\n",
       "      <td>0.689188</td>\n",
       "      <td>7.31942</td>\n",
       "      <td>24.0964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifierWithCat</th>\n",
       "      <td>0.809277</td>\n",
       "      <td>0.640305</td>\n",
       "      <td>11.9167</td>\n",
       "      <td>529.485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Accuracy   ROC-AUC Training_time Prediction_time\n",
       "GaussianNBbaseline            0.748094  0.745322      0.362021        0.146008\n",
       "GaussianNBnoCat                0.83572  0.732009     0.0370018       0.0110009\n",
       "GaussianNBwithCat             0.772455  0.734941      0.138008       0.0600033\n",
       "LogisticRegressionBaseline    0.847056  0.684625       2.38414       0.0290015\n",
       "LogisticRegressionNoCat       0.851023   0.69869      0.130008     0.000999928\n",
       "LogisticRegressionWithCat     0.851529  0.713009       0.52303      0.00500011\n",
       "KNeighborsClassifierBaseline  0.832794  0.701302        17.538         140.023\n",
       "KNeighborsClassifierNoCat     0.831444  0.689188       7.31942         24.0964\n",
       "KNeighborsClassifierWithCat   0.809277  0.640305       11.9167         529.485"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZcOGx4_3RWl"
   },
   "source": [
    "\n",
    "\n",
    "*   baseline - способ 1. one-hot-encoding + мода\n",
    "*   WithCat - спосбо 2. убраны коррелирующие признаки, признаки отскалированны, one-hot-encoding + мода\n",
    "*   NoCat - способ 3. убраны коррелирующие признаки, признаки отскалированны, убраны категориальные данные. one-hot-encoding + мода\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRqb-Bp-1dRG"
   },
   "source": [
    "Итак, как видно из таблицы выше, логистическая регрессия справилась с задачей лучше всего, показав результат близкий к 0.9.<br>\n",
    "Это означает, что в пространстве признаков, можно построить такую прямую, которая почти безошибочно разделяла бы целевую переменную. <br>\n",
    "По быстродействию этот метод оказался незначительно хуже наивного Байеса и значительно быстрее К-ближайших-соседей. <br>\n",
    "Что касается других методов, то наивный байес показал себя неплохо, верно разделив около 80% данных. Примерно так же справился и метод К-ближайших-соседей. Однако в его случае, время на тренировку и предсказание значительно больше той же логистической регресси (15 с. против 0.14 с. при наилучших результатах)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "technopark_hw1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
